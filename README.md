Natural Cosmetics Shop Analysis

1. Description

This project analyzes a mock dataset of a natural cosmetics shop, exploring product performance, customer behavior, and sales patterns. Using SQL, Python, and Power BI, the analysis identifies key trends, top-selling categories, inventory patterns, and potential growth opportunities. The project includes data cleaning, exploratory analysis, visual dashboards, and structured documentation to demonstrate practical data-analysis skills in a retail and cosmetics context.
 
**DISCLAIMER**

This project is based on a fictional natural cosmetics shop.
All datasets were randomly generated using Mockaroo.com for educational and portfolio purposes. The shop, customers, orders, and all business entities do not represent any real company or real individuals.

2. Structure

|_tables/            *#raw data and processed tables*

|_sql/               *#sql queries*

|_notebooks/         *#python (etl and eda)*

|_powerbi/           *#dashboard*

|_documentation/     *#pipelines*
   
3. Tools and technologies

1) Python (pandas, numpy, matplotlib, seaborn)
   
2) SQL (postgresql)

3) Power BI (visualisation)

4) Mockaroo (data generation)

5) Jupiter notebook

4. Key steps

- Data generation and collection

- Data cleaning (ETL)

- EDA (exploratory data analysis)

- Visualization in Python

- SQL analysis

- Power BI interactive dashboard

- Conclusions

5. Screenshots
   
   1) Power BI dashboard (part)

  <img width="754" height="431" alt="image" src="https://github.com/user-attachments/assets/d8d8cd33-5579-439d-92c1-46fa70525212" />

  2) EDA (Jupiter)

  <img width="863" height="542" alt="image" src="https://github.com/user-attachments/assets/deef9302-5341-4ec5-9939-a7789a2454a4" />

  <img width="654" height="494" alt="image" src="https://github.com/user-attachments/assets/8f880577-cdc7-4731-908c-f75de4d039b2" />

 6. How to use/open

SQL queries: 

The SQL scripts were written for PostgreSQL.  

To run them:

1) Create a PostgreSQL database.

2) Import the CSV files from the `tables/` folder.

3) Open the `.sql` files in pgAdmin Query Tool.

4) Run them

Python 

The Python analysis is located in the `notebooks/` folder.  

To run the notebooks:

1) Install Python 3.10+

2) Launch Jupiter Notebook

3) Open .ipnyb files (etl and eda)

4) Make sure the CSV files from the tables/ folder are in the same directory structure so the notebooks can load them correctly.

Power BI

Dashboard is located in the `powerbi` folder.

1) Download .pbix file

2) Open it in Power BI Desktop 

7. Results and insights

In `documentation/` folder: structure.pdf

8. Author

Galiia Islamova
